g
g <- g + geom_point(aes(colour=factor(mtcars$am)))
g
mtcars$am
g <- g + geom_point(
)
g
g <- ggplot(mtcars, aes(am, mpg))
g <- g + geom_point()
g
g <- g + geom_smooth()
g
g <- g + geom_smooth(method="lm")
g
g <- ggplot(mtcars, aes(am, mpg))
g <- g + geom_point()
g <- g + geom_smooth(method="lm")
g
fit <- lm(mpg ~ am, data=mtcars)
summary(fit)
library(ggplot2)
g <- ggplot(mtcars, aes(as.factor(am), wt))
g <- geom_boxplot()
g
as.factor
as.factor(mtcars$am)
mtcars$am <- as.factor(mtcars$am)
g <- ggplot(mtcars, aes(factor(am), wt))
g <- geom_boxplot()
g
p <- ggplot(mtcars, aes(mpg, wt)) + geom_point()
# With one variable
p + facet_grid(. ~ cyl)
p <- ggplot(mtcars, aes(mpg, wt)) + geom_point()
# With one variable
p + facet_grid(mpg ~ cyl)
p <- ggplot(mtcars, aes(mpg, wt)) + geom_point()
# With one variable
p + facet_grid(. ~ cyl)
p <- ggplot(mtcars, aes(wt, mpg)) + geom_point()
# With one variable
p + facet_grid(. ~ as.factor(am))
p <- ggplot(mtcars, aes(wt, mpg)) + geom_point()
# With one variable
p + facet_grid(. ~ am)
p <- ggplot(mtcars, aes(wt, mpg)) + geom_point()
# With one variable
p <- p + facet_grid(. ~ am)
p <- p + geom_smooth(method="lm")
p
resid(fit)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(I(y - mean(y)) ~ I(x - mean(x)) - 1)
lm(y ~ x - 1)
install.packages("AppliedPredictiveModeling")
install.packages("caret")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
qplot(Superplasticizer, data=training, geom="histogram")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
head(predictors)
?grep
grep("IL", colnames(predictors), fixed=TRUE)
beginIL <- grep("IL", colnames(predictors), fixed=TRUE)
?prcomp
beginIL
preProcess(predictors[beginIL,], method="pca")
?preProcess
preProcess(predictors[beginIL,], method="pca", thesh=.90)
preProcess(predictors[beginIL,], method="pca", thresh=.90)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
beginIL <- grep("IL", colnames(predictors), fixed=TRUE)
beginIL <- predictors[beginIL,]
beginIL
beginIL <- grep("IL", colnames(predictors), fixed=TRUE)
beginIL
beginIL <- predictors[,beginIL]
beginIL
View(beginIL)
View(predictors)
View(training)
View(predictors)
mydata <- data.frame(diagnosis, beginIL)
View(mydata)
pca <- train(diagnosis ~ ., method="glm", data=mydata)
install.packages("e1071")
pca <- train(diagnosis ~ ., method="glm", data=mydata)
nonpca <- train(diagnosis ~ ., method="glm", data=mydata)
preProcess(mydata[,-1], method="pca", thresh=.80)
pcadata <- data.frame(diagnosis,preProcess(mydata[,-1], method="pca", thresh=.80))
pcaPredictors <- preProcess(mydata[,-1], method="pca", thresh=.80)
pcaPredictors
View(testing)
nonpca
?train
trainPC <- predict(pcaPredictors, mydata[,-1])
View(trainPC)
pca <- train(diagnosis ~ ., method="glm", data=trainPC)
pca
trainPC
View(trainPC)
newdata <- data.frame(diagnosis, trainPC)
train(diagnosis ~ ., method="glm", data=newdata)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
beginIL <- grep("IL", colnames(predictors), fixed=TRUE)
beginIL <- predictors[,beginIL]
newdata <- data.frame(diagnosis, beginIL)
View(newdata)
preProc <- preProcess(newdata[,-1], method="pca", thresh=0.80)
?preProcess
preProc
preProc <- predict.preProcess(newdata[,-1], method="pca", thresh=0.80)
preProc <- predict.preProcess(newdata[,-1], method="pca", thresh=0.80)
preProc <- preProcess(newdata[,-1], method="pca", thresh=0.80)
trainPC <- predict(preProc, newdata[,-1])
View(trainPC)
newdata <- data.frame(diagnosis, trainPC)
View(newdata)
pca <- train(diagnosis ~ ., method="glm", data=newdata)
pca
?cTreeBag
ctreeBag
?ctreeBag
install.packages("ctreeBag")
library(ctreeBag)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Case, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
modFit <- train(Case~., data=training, method="rpart")
modFit$finalModel
head(training$Case)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training <- segmentationOriginal[segmentationOriginal$Case == "Train",]
testing <- segmentationOriginal[segmentationOriginal$Case == "Test",]
head(training)
modFit <- train(Class~., data=training, method="rpart")
modFit$finalModel
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
modFit <- train(Area~., data=olive, method="rpart")
predict(modFit, newdata = newdata)
summary(olive$Area)
head(olive$Area)
tail(olive$Area)
class(olive$Area)
range(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
colnames(SAheart)
modFit <- train(chd~age+alcohol+obesity+tobacco+typea+ldl, data=trainSA, method="glm", family="binomial")
modFit$finalModel
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA, predict(modFit, newdata))
missClass(trainSA, predict(modFit, newdata=trainSA))
missClass(trainSA$chd, predict(modFit, newdata=trainSA))
missClass(trainSA$chd, predict(modFit, newdata=testSA))
missClass(testSA$chd, predict(modFit, newdata=testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
modFit <- train(y~., data=vowel.train, method="rf")
modFit$finalModel
varImp(modFit)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train[,y] <- as.factor(vowel.train[,y])
vowel.train$y <- as.factor(vowel.train$y)
set.seed(33833)
rfFit <- train(y~., data=vowel.train, method="rf")
gbmFit <- train(y~., data=vowell.train, method="gbm")
gbmFit <- train(y~., data=vowel.train, method="gbm")
gbmFit$results
rfFit$finalModel
predict(rfFit, vowel.train)
compare_models(rfFit,gbmFit)
gbmFit$finalModel
gbmFit$results
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
pred1 <- train(diagnosis~., data=training, method="rf")
pred2 <- train(diagnosis~., data=training, method="gbm")
pred3 <- train(diagnosis~., data=training, method="lda")
dataStack <- cbind(predict(pred1, testing), predict(pred2, testing), predict(pred3, testing), testing$diagnosis)
View(dataStack)
colnames(dataStack$V4) <- diagnosis
colnames(dataStack[,4]) <- diagnosis
colnames(dataStack) <- c("1","2","3","diagnosis")
View(dataStack)
stacked <- train(diagnosis~., data=dataStack, method="rf")
stacked$finalModel
pred1$finalModel
stacked$results
pred1$results
pred2$results
pred3$results
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod <- train(CompressiveStrengrh~., data=training, method="lasso")
mod <- train(CompressiveStrength~., data=training, method="lasso")
?plot.enet
plot.enet(mod)
mod$finalModel
plot.enet(x=mod)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
rf <- train(y~., data=vowel.train, method="rf")
library(caret)
rf <- train(y~., data=vowel.train, method="rf")
gbm <- train(y~., data=vowel.train, method="gbm")
confusionMatrix(predict(rf,newdata = vowel.test), vowel.test$y)
confusionMatrix(predict(gbm,newdata = vowel.test), vowel.test$y)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
rf <- train(diagnosis~., data=training, method="rf")
gbm <- train(diagnosis~., data=training, method="gbm")
lda <- train(diagnosis~., data=training, method="lda")
rfmatrix <- confusionMatrix(predict(rf,newdata = testing), testing$diagnosis)
gbmmatrix <- confusionMatrix(predict(gbm,newdata = testing), testing$diagnosis)
ldamatrix <- confusionMatrix(predict(lda,newdata = testing), testing$diagnosis)
rfmatrix
gbmmatrix
ldamatrix
stackedData <- data.frame(predict(rf,newdata=testing),predict(gbm,newdata=testing),predict(lda,newdata=testing), diagnosis=testing$diagnosis)
stackedData
View(stackedData)
stack <- train(diagnosis~., data=stackedData, method="rf")
confusionMatrix(predict(stack, testing$diagnosis), testing$diagnosis)
confusionMatrix(predict(stack, newdata=testing$diagnosis), testing$diagnosis)
predict(stack, newdata = testing)
predict(stack, newdata = testing)
stack <- train(diagnosis~., data=stackedData, method="rf")
stack$finalModel
predict(stack, newdata = testing)
predict(stack$method, newdata = testing)
predict(stack$modelInfo, newdata = testing)
predict(stack$modelInfo$fit(), newdata = testing)
predict(stack$modelInfo$fit, newdata = testing)
predict(stack$modelInfo$predict(), newdata = testing)
predict(stack$modelInfo$predict, newdata = testing)
predict(stack, newdata = testing)
predict(stack, newdata = stackedData)
finalpred <- predict(stack, newdata = stackedData)
confusionMatrix(finalpred, testing$diagnosis)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
fit <- train(CompressiveStrength~., data=training, method="lasso")
plot.enet(fit)
?plot.enet
plot.enet(fit, penalty)
plot.enet(fit, xvar=penalty)
plot.enet(fit, xvar="penalty")
plot.enet(fit, xvar="penalty")
attach(training)
plot.enet(fit, xvar="penalty")
fit$finalModel
class(fit)
fit$modelType
fit$call
fit$control
plot.enet(fit$finalModel)
plot.enet(fit$finalModel, "penalty")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
install.packages("lubridate")
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("~/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
?bats
library(forecast)
install.packages("forecast")
library(forecast)
?bats
bats(tstrain)
fit <- bats(tstrain)
forecast(fit)
confusionMatrix(forecast(fit), testing$visitsTumblr)
fcast <- forecast(fit)
tstest(testing)
tstest <- ts(testing)
tstest <- ts(testing$visitsTumblr)
accuracy(fcast,tstest)
fcast <- forecast(fit, h = 235)
accuracy(fcast,tstest)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(lubridate)  # For year() function below
dat = read.csv("~/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
fit <- bats(tstrain)
fcast <- forecast(fit, h = 235)
tstest <- ts(testing$visitsTumblr)
accuracy(fcast, tstest)
table(fcast$fitted, tstest)
length(fcast$fitted)
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
e1071
?e1071
library(e1071)
?e1071
??e1071
set.seed(325)
fit <- svm(CompressiveStrength~., data=training)
predict(svm, newdata=testing)
predict(fit, testing)
pred <- predict(fit, testing)
confusionMatrix(pred, testing$CompressiveStrength)
class(testing$CompressiveStrength)
pred <- as.numeric(pred)
confusionMatrix(pred, testing$CompressiveStrength)
levels(pred)
levels(testing$CompressiveStrength)
length(pred)
length(testing$CompressiveStrength)
confusionMatrix(testing$CompressiveStrength, pred)
?confusionMatrix
testing$CompressiveStrength
confusionMatrix(predict(fit, testing), testing$CompressiveStrength)
table(pred, testing$CompressiveStrength)
length(pred)
confusionMatrix(pred, testing$CompressiveStrength)
table(factor(pred, levels=min(test):max(test)),factor(test, levels=min(test):max(test)))
table(factor(pred, levels=min(testing$CompressiveStrength):max(testing$CompressiveStrength)),factor(testing$CompressiveStrength, levels=min(testing$CompressiveStrength):max(testing$CompressiveStrength)))
res <- testing$CompressiveStrength - pred
res^2
res <- res^2
sqrt(sum(res)/length(res))
install.packages("DDPQuiz3")
library(DDPQuiz3)
?vCorpus
library(tm)
?vCorpus
?VCorpus
?VectorSource
getSources()
load("~/github/DataScienceCapstone/data/prepared-data-sets/.RData")
library(tm)
library(SnowballC)
library(RWeka)
plot(ngrams)
install.packages('Rgraphviz')
inspect(removeSparseTerms(ngrams, .4))
inspect(tdm[1:5, 5000:5015])
inspect(ngrams[1:5, 5000:5015])
inspect(removeSparseTerms(ngrams, .9))
tail(ngrams$dimnames$Terms)
head(ngrams$dimnames$Terms)
inspect(removeSparseTerms(ngrams, .1))
?removePunctuation
termFreq(ngrams)
summary(ngrams)
inspect(as.character(training[[1:5]]))
inspect(as.character(training[1:5))
inspect(as.character(training[1:5)
inspect(as.character(training[1:5]))
as.character(training[1:5])
as.character(training[[[1:5]])
as.character(training[[1:5]])
setwd("~/github/DataScienceCapstone/assignments")
save(training, file="training.RData")
load('training.RData')
as.character(training[[1]])
as.character(training[[50000]])
as.character(training[[99999]])
load('training.RData')
as.character(training[[1]])
as.character(training[[50000]])
as.character(training[[99999]])
load('training.RData')
as.character(training[[1]])
as.character(training[[50000]])
as.character(training[[99999]])
as.character(training[[50000]])
as.character(training[[50000]])
source('training.RData')
load('training.RData')
as.character(training[[1]])
as.character(training[[50000]])
as.character(training[[99999]])
save(ngrams, file="ngrams.RData")
setwd("~/github/DataScienceCapstone/assignments")
load("~/github/DataScienceCapstone/assignments/training.RData")
as.character(training[[1]])
as.character(training[[5]])
as.character(training[[45000]])
rowSums(as.matrix(ngrams))
findFreqTerms(ngrams, 1000)
ngrams
